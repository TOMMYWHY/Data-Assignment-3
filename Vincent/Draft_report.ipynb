{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 158.755 Data Science - Making Sense of Data Project 4\n",
    "# Study In Recommendation Engine"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Abstract\n",
    "\n",
    "A recommender system, or a recommendation engine intends to seek prediction of 'rating' or 'preference' for a user that would rank an item or event, mainly used in commercial web applications. \n",
    "\n",
    "They have been utilized in various areas over the last ten years, commonly used as playlist generators for video and music services such as Youtube, Netflix, and BiliBili, product recommenders like Amazon, Trademe, and Ebay, and content or news based recommenders for social media platforms as Facebook, Twitter and Instergram. Also, there are other popular recommender systems being utilized for specific topics as hotels booking, dating matching, and online competition game team up.\n",
    "\n",
    "Flow and monetization are the core concept associated with commercial web applications for internet. Simply speaking, flow is the measurement that the number of visitings for a web application, while monetization evaluates its overall income for keeping the business up and running continuously and healthily. (i.e. advertisement income of Youtube, membership subscriptions for Netflix, and fees/charges for each successfully sale for Amazon ). \n",
    "\n",
    "Therefore, recommendation engine is one of the key part for monetization that allows finding consumers' real demand through directing them to their most interest items or services. In addition to this , owners of commercial web applications, would be able accurately deploy advertisements and services to their customers based on a successful recommendation engine set up, for example ,playlist generators (Youtube) could generate just right advertisements to their viewers , and product recommenders like Amazon could pushed customers related products when they are viewing a certain item. Thus, it would optimise the resource usage and amplify income for a commercial organisation who has developed such kind of commercial web applications. \n",
    "\n",
    "In this project , we would implement a ***'breath first'*** strategy so as to explore as much lifecycle and implementations for a recommendation engine , such as the input and output data structure, machine learning algorithms, evaluation standard for comparison of different algorithms, and its position and role in architecture of a commercial web applications , instead of undertaking ***in-depth*** research on specific algorithms as per their theory and implementations. Thus, we will simply use an existing library to compute our findings and recommendations for this project.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Indroduction\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Collection\n",
    "\n",
    "The datasets for a commercial web application have almost never been exposed for public usage or research, as they are private and strategy assets for business. Normally they are generated through \n",
    "\n",
    "Fortunately, there are existing web source regarding recommendation engine study for us to play with , which is Amazon product data prepared by Associate Professor Julian McAuley, UCSD at http://jmcauley.ucsd.edu/data/amazon/.\n",
    "\n",
    "Normally, user activates for a commercial web app could be concluded as viewing a certain web page , purchasing products, comments and rank items , content or news etc. It is quite difficult to summarise a standard data structure for a recommendation engine due to the variety demands and requirements for various business activities.\n",
    "\n",
    "However, a classic data structure format has been widely used after long term experimentation and operation with major internet giant companies such as Amazon and Facebook:\n",
    "\n",
    "- ***user id*** : unique user id\n",
    "- ***item id*** : unique item id\n",
    "- ***behaviour type*** : type of behaviour , i.e. purchase or view an item\n",
    "- ***context*** : behaviour context, including location and time etc.\n",
    "- ***behaviour weight*** : weight could be the viewing length for a video or rank for an item \n",
    "- ***behaviour content*** : if a user comments something, the content could be saved as a text file. If user click an item, the content could be a binary input.\n",
    "\n",
    "\n",
    "### Web API\n",
    "\n",
    "Amazon Instant Video review data , http://snap.stanford.edu/data/amazon/productGraph/categoryFiles/reviews_Amazon_Instant_Video_5.json.gz , has been selected as the dataset for this project. \n",
    "\n",
    "\n",
    "\n",
    "\n",
    "### Web Crawling"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## EDA"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Algorithm Research"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import defaultdict\n",
    "from surprise import Dataset\n",
    "import pandas as pd\n",
    "from surprise import SVD\n",
    "from surprise import NormalPredictor\n",
    "from surprise import Dataset\n",
    "from surprise import Reader\n",
    "from surprise.model_selection import cross_validate\n",
    "import numpy as np\n",
    "from surprise import dump\n",
    "import os\n",
    "from surprise.model_selection import KFold\n",
    "import io  # needed because of weird encoding of u.item file\n",
    "\n",
    "from surprise import KNNBaseline\n",
    "from surprise import get_dataset_dir\n",
    "\n",
    "def precision_recall_at_k(predictions, k=10, threshold=3.5):\n",
    "    '''Return precision and recall at k metrics for each user.'''\n",
    "\n",
    "    # First map the predictions to each user.\n",
    "    user_est_true = defaultdict(list)\n",
    "    for uid, _, true_r, est, _ in predictions:\n",
    "        user_est_true[uid].append((est, true_r))\n",
    "\n",
    "    precisions = dict()\n",
    "    recalls = dict()\n",
    "    for uid, user_ratings in user_est_true.items():\n",
    "\n",
    "        # Sort user ratings by estimated value\n",
    "        user_ratings.sort(key=lambda x: x[0], reverse=True)\n",
    "\n",
    "        # Number of relevant items\n",
    "        n_rel = sum((true_r >= threshold) for (_, true_r) in user_ratings)\n",
    "\n",
    "        # Number of recommended items in top k\n",
    "        n_rec_k = sum((est >= threshold) for (est, _) in user_ratings[:k])\n",
    "\n",
    "        # Number of relevant and recommended items in top k\n",
    "        n_rel_and_rec_k = sum(((true_r >= threshold) and (est >= threshold))\n",
    "                              for (est, true_r) in user_ratings[:k])\n",
    "\n",
    "        # Precision@K: Proportion of recommended items that are relevant\n",
    "        precisions[uid] = n_rel_and_rec_k / n_rec_k if n_rec_k != 0 else 1\n",
    "\n",
    "        # Recall@K: Proportion of relevant items that are recommended\n",
    "        recalls[uid] = n_rel_and_rec_k / n_rel if n_rel != 0 else 1\n",
    "\n",
    "    return precisions, recalls\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### SVD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "best RMSE score\n",
      "1.0273052571444052\n",
      "0.7624481094830237\n",
      "combination of parameters that gave the best RMSE score\n",
      "{'n_epochs': 15, 'lr_all': 0.01, 'reg_all': 0.2}\n",
      "{'n_epochs': 15, 'lr_all': 0.01, 'reg_all': 0.2}\n"
     ]
    }
   ],
   "source": [
    "from surprise import SVD\n",
    "from surprise import Dataset\n",
    "from surprise.model_selection import GridSearchCV\n",
    "\n",
    "df = pd.read_csv('full_dataset.csv')\n",
    "# A reader is still needed but only the rating_scale param is requiered.\n",
    "reader = Reader(rating_scale=(1, 5))\n",
    "\n",
    "# The columns must correspond to user id, item id and ratings (in that order).\n",
    "data = Dataset.load_from_df(df[['userID', 'itemID', 'rating']], reader)\n",
    "\n",
    "#choose various parameters for model\n",
    "param_grid = {'n_epochs': [5, 10,15], 'lr_all': [0.002, 0.005,0.01],\n",
    "              'reg_all': [0.2, 0.4, 0.6]}\n",
    "\n",
    "#iterate thorugh parameter grid to find best model\n",
    "gs = GridSearchCV(SVD, param_grid, measures=['rmse', 'mae'], cv=3)\n",
    "\n",
    "gs.fit(data)\n",
    "\n",
    "# best RMSE score\n",
    "print('best RMSE score')\n",
    "print(gs.best_score['rmse'])\n",
    "print(gs.best_score['mae'])\n",
    "# combination of parameters that gave the best RMSE score\n",
    "print('combination of parameters that gave the best RMSE score')\n",
    "print(gs.best_params['rmse'])\n",
    "print(gs.best_params['mae'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "precision@k\n",
      "0.9056838372698603\n",
      "recall@k\n",
      "0.8122341971254446\n",
      "precision@k\n",
      "0.9031010602439188\n",
      "recall@k\n",
      "0.8142918035172808\n",
      "precision@k\n",
      "0.9052896754349741\n",
      "recall@k\n",
      "0.8111687175038439\n",
      "precision@k\n",
      "0.9050548802438796\n",
      "recall@k\n",
      "0.8097509651491113\n",
      "precision@k\n",
      "0.903617541447018\n",
      "recall@k\n",
      "0.8107720699323242\n"
     ]
    }
   ],
   "source": [
    "kf = KFold(n_splits=5)\n",
    "#best algo based on above\n",
    "algo = gs.best_estimator['rmse']\n",
    "#print precision@k and recall@k\n",
    "for trainset, testset in kf.split(data):\n",
    "    algo.fit(trainset)\n",
    "    predictions = algo.test(testset)\n",
    "    precisions, recalls = precision_recall_at_k(predictions, k=5, threshold=4)\n",
    "\n",
    "    # Precision and recall can then be averaged over all users\n",
    "    print('precision@k')\n",
    "    print(sum(prec for prec in precisions.values()) / len(precisions))\n",
    "    print('recall@k')\n",
    "    print(sum(rec for rec in recalls.values()) / len(recalls))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "#save the model for later use\n",
    "dump.dump(os.path.expanduser(\"SVD_GS_BEST_RMSE\"), algo=gs.best_estimator['rmse'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cosine Similarity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Estimating biases using als...\n",
      "Computing the cosine similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Estimating biases using als...\n",
      "Computing the cosine similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Estimating biases using als...\n",
      "Computing the cosine similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Estimating biases using als...\n",
      "Computing the cosine similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Estimating biases using als...\n",
      "Computing the cosine similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Evaluating RMSE, MAE of algorithm KNNBaseline on 5 split(s).\n",
      "\n",
      "                  Fold 1  Fold 2  Fold 3  Fold 4  Fold 5  Mean    Std     \n",
      "RMSE (testset)    1.0877  1.0845  1.0827  1.0826  1.0855  1.0846  0.0019  \n",
      "MAE (testset)     0.7407  0.7390  0.7382  0.7378  0.7383  0.7388  0.0010  \n",
      "Fit time          49.62   280.10  307.70  56.33   82.74   155.30  114.04  \n",
      "Test time         9.07    149.09  97.32   69.34   40.16   73.00   48.09   \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'test_rmse': array([1.08774203, 1.08446025, 1.08267142, 1.08255709, 1.08551081]),\n",
       " 'test_mae': array([0.74068957, 0.73899557, 0.73816598, 0.73776043, 0.73833932]),\n",
       " 'fit_time': (49.61555480957031,\n",
       "  280.0983302593231,\n",
       "  307.70160937309265,\n",
       "  56.328015089035034,\n",
       "  82.74313378334045),\n",
       " 'test_time': (9.068887710571289,\n",
       "  149.0948407649994,\n",
       "  97.32177829742432,\n",
       "  69.33917331695557,\n",
       "  40.16020727157593)}"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sim_options = {'name': 'cosine', 'user_based': False} # or item based\n",
    "algo = KNNBaseline(sim_options=sim_options)\n",
    "cross_validate(algo, data, measures=['RMSE', 'MAE'], cv=5, verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Estimating biases using als...\n",
      "Computing the cosine similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "precision@k\n",
      "0.8971717241273791\n",
      "recall@k\n",
      "0.791610061030033\n",
      "Estimating biases using als...\n",
      "Computing the cosine similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "precision@k\n",
      "0.8950178931316445\n",
      "recall@k\n",
      "0.7913077032646899\n",
      "Estimating biases using als...\n",
      "Computing the cosine similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "precision@k\n",
      "0.8981713917229017\n",
      "recall@k\n",
      "0.7895691976528738\n",
      "Estimating biases using als...\n",
      "Computing the cosine similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "precision@k\n",
      "0.8968833226191572\n",
      "recall@k\n",
      "0.7893254046291424\n",
      "Estimating biases using als...\n",
      "Computing the cosine similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "precision@k\n",
      "0.8975616193142721\n",
      "recall@k\n",
      "0.7904921824778635\n"
     ]
    }
   ],
   "source": [
    "kf = KFold(n_splits=5)\n",
    "#best algo based on above\n",
    "sim_options = {'name': 'cosine', 'user_based': False} # or item based\n",
    "algo = KNNBaseline(sim_options=sim_options)\n",
    "#print precision@k and recall@k\n",
    "for trainset, testset in kf.split(data):\n",
    "    algo.fit(trainset)\n",
    "    predictions = algo.test(testset)\n",
    "    precisions, recalls = precision_recall_at_k(predictions, k=5, threshold=4)\n",
    "\n",
    "    # Precision and recall can then be averaged over all users\n",
    "    print('precision@k')\n",
    "    print(sum(prec for prec in precisions.values()) / len(precisions))\n",
    "    print('recall@k')\n",
    "    print(sum(rec for rec in recalls.values()) / len(recalls))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "#save the model for later use\n",
    "dump.dump(os.path.expanduser(\"KNN_COSINE\"), algo=algo)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get Top N Items "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_top_n(predictions, n=10):\n",
    "    '''Return the top-N recommendation for each user from a set of predictions.\n",
    "\n",
    "    Args:\n",
    "        predictions(list of Prediction objects): The list of predictions, as\n",
    "            returned by the test method of an algorithm.\n",
    "        n(int): The number of recommendation to output for each user. Default\n",
    "            is 10.\n",
    "\n",
    "    Returns:\n",
    "    A dict where keys are user (raw) ids and values are lists of tuples:\n",
    "        [(raw item id, rating estimation), ...] of size n.\n",
    "    '''\n",
    "\n",
    "    # First map the predictions to each user.\n",
    "    top_n = defaultdict(list)\n",
    "    for uid, iid, true_r, est, _ in predictions:\n",
    "        top_n[uid].append((iid, est))\n",
    "\n",
    "    # Then sort the predictions for each user and retrieve the k highest ones.\n",
    "    for uid, user_ratings in top_n.items():\n",
    "        user_ratings.sort(key=lambda x: x[1], reverse=True)\n",
    "        top_n[uid] = user_ratings[:n]\n",
    "\n",
    "    return top_n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get the k nearest neighbors of a user (or item)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[3, 12, 28, 40, 66, 67, 72, 77, 80, 95]"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "algo.get_neighbors(int(10000), k=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Presentation of Web App"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Recommendation Engine in System Architecture "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
