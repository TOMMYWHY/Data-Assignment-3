{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import defaultdict\n",
    "from surprise import Dataset\n",
    "import pandas as pd\n",
    "from surprise import SVD\n",
    "from surprise import NormalPredictor\n",
    "from surprise import Dataset\n",
    "from surprise import Reader\n",
    "from surprise.model_selection import cross_validate\n",
    "import numpy as np\n",
    "from surprise import dump\n",
    "import os\n",
    "from surprise.model_selection import KFold\n",
    "import io  # needed because of weird encoding of u.item file\n",
    "\n",
    "from surprise import KNNBaseline\n",
    "from surprise import get_dataset_dir\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def precision_recall_at_k(predictions, k=10, threshold=3.5):\n",
    "    '''Return precision and recall at k metrics for each user.'''\n",
    "\n",
    "    # First map the predictions to each user.\n",
    "    user_est_true = defaultdict(list)\n",
    "    for uid, _, true_r, est, _ in predictions:\n",
    "        user_est_true[uid].append((est, true_r))\n",
    "\n",
    "    precisions = dict()\n",
    "    recalls = dict()\n",
    "    for uid, user_ratings in user_est_true.items():\n",
    "\n",
    "        # Sort user ratings by estimated value\n",
    "        user_ratings.sort(key=lambda x: x[0], reverse=True)\n",
    "\n",
    "        # Number of relevant items\n",
    "        n_rel = sum((true_r >= threshold) for (_, true_r) in user_ratings)\n",
    "\n",
    "        # Number of recommended items in top k\n",
    "        n_rec_k = sum((est >= threshold) for (est, _) in user_ratings[:k])\n",
    "\n",
    "        # Number of relevant and recommended items in top k\n",
    "        n_rel_and_rec_k = sum(((true_r >= threshold) and (est >= threshold))\n",
    "                              for (est, true_r) in user_ratings[:k])\n",
    "\n",
    "        # Precision@K: Proportion of recommended items that are relevant\n",
    "        precisions[uid] = n_rel_and_rec_k / n_rec_k if n_rec_k != 0 else 1\n",
    "\n",
    "        # Recall@K: Proportion of relevant items that are recommended\n",
    "        recalls[uid] = n_rel_and_rec_k / n_rel if n_rel != 0 else 1\n",
    "\n",
    "    return precisions, recalls\n",
    "\n",
    "def get_top_n(predictions, n=10):\n",
    "    '''Return the top-N recommendation for each user from a set of predictions.\n",
    "\n",
    "    Args:\n",
    "        predictions(list of Prediction objects): The list of predictions, as\n",
    "            returned by the test method of an algorithm.\n",
    "        n(int): The number of recommendation to output for each user. Default\n",
    "            is 10.\n",
    "\n",
    "    Returns:\n",
    "    A dict where keys are user (raw) ids and values are lists of tuples:\n",
    "        [(raw item id, rating estimation), ...] of size n.\n",
    "    '''\n",
    "\n",
    "    # First map the predictions to each user.\n",
    "    top_n = defaultdict(list)\n",
    "    for uid, iid, true_r, est, _ in predictions:\n",
    "        top_n[uid].append((iid, est))\n",
    "\n",
    "    # Then sort the predictions for each user and retrieve the k highest ones.\n",
    "    for uid, user_ratings in top_n.items():\n",
    "        user_ratings.sort(key=lambda x: x[1], reverse=True)\n",
    "        top_n[uid] = user_ratings[:n]\n",
    "\n",
    "    return top_n\n",
    "\n",
    "def train_and_save_prediction_model (file_to_save) :\n",
    "    #train and save model\n",
    "\n",
    "    df = pd.read_csv('testForInput.csv')\n",
    "    # A reader is still needed but only the rating_scale param is requiered.\n",
    "    reader = Reader(rating_scale=(1, 5))\n",
    "\n",
    "    # The columns must correspond to user id, item id and ratings (in that order).\n",
    "    data = Dataset.load_from_df(df[['userID', 'itemID', 'rating']], reader)\n",
    "    trainset = data.build_full_trainset()\n",
    "    #train data with algorithm\n",
    "    algo = SVD()\n",
    "    #cross_validate(algo, data, measures=['RMSE', 'MAE'], cv=5, verbose=True)\n",
    "    algo.fit(trainset)\n",
    "    # Dump algorithm and reload it.\n",
    "    file_name = os.path.expanduser(file_to_save)\n",
    "    dump.dump(file_name, algo=algo)\n",
    "\n",
    "def train_and_save_similarity_model(file_to_save):\n",
    "    df = pd.read_csv('testForInput.csv')\n",
    "    # A reader is still needed but only the rating_scale param is requiered.\n",
    "    reader = Reader(rating_scale=(1, 5))\n",
    "\n",
    "    # The columns must correspond to user id, item id and ratings (in that order).\n",
    "    data = Dataset.load_from_df(df[['userID', 'itemID', 'rating']], reader)\n",
    "    trainset = data.build_full_trainset()\n",
    "    sim_options = {'name': 'cosine', 'user_based': True} # or item based\n",
    "    algo = KNNBaseline(sim_options=sim_options)\n",
    "    algo.fit(trainset)\n",
    "    \n",
    "    # Dump algorithm and reload it.\n",
    "    file_name = os.path.expanduser(file_to_save)\n",
    "    dump.dump(file_name, algo=algo)\n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "def load_model_from_disk(file_to_load):\n",
    "    file_name = os.path.expanduser(file_to_load) # 'SVD_dump_file'\n",
    "    _, loaded_algo = dump.load(file_name)\n",
    "    return loaded_algo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_and_save_prediction_model ('SVD_dump_file')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Estimating biases using als...\n",
      "Computing the cosine similarity matrix...\n",
      "Done computing similarity matrix.\n"
     ]
    }
   ],
   "source": [
    "train_and_save_similarity_model('KNNbaseline_dump_file')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "prediction_algo = load_model_from_disk('SVD_dump_file')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "knn_algo = load_model_from_disk('KNNbaseline_dump_file')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>item_id</th>\n",
       "      <th>item_name</th>\n",
       "      <th>img_url</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0700026657</td>\n",
       "      <td>– Arcane Raise –</td>\n",
       "      <td>https://igg-games.com/wp-content/uploads/2018/...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>6050036071</td>\n",
       "      <td>– Occult preRaise –</td>\n",
       "      <td>https://igg-games.com/wp-content/uploads/2018/...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>9629971372</td>\n",
       "      <td>!4RC4N01D!</td>\n",
       "      <td>https://igg-games.com/wp-content/uploads/2018/...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>9882106463</td>\n",
       "      <td>– Arcane Raise –</td>\n",
       "      <td>https://igg-games.com/wp-content/uploads/2018/...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>B000006OVL</td>\n",
       "      <td>– Occult preRaise –</td>\n",
       "      <td>https://igg-games.com/wp-content/uploads/2018/...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      item_id            item_name  \\\n",
       "0  0700026657     – Arcane Raise –   \n",
       "1  6050036071  – Occult preRaise –   \n",
       "2  9629971372           !4RC4N01D!   \n",
       "3  9882106463     – Arcane Raise –   \n",
       "4  B000006OVL  – Occult preRaise –   \n",
       "\n",
       "                                             img_url  \n",
       "0  https://igg-games.com/wp-content/uploads/2018/...  \n",
       "1  https://igg-games.com/wp-content/uploads/2018/...  \n",
       "2  https://igg-games.com/wp-content/uploads/2018/...  \n",
       "3  https://igg-games.com/wp-content/uploads/2018/...  \n",
       "4  https://igg-games.com/wp-content/uploads/2018/...  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_data = pd.read_csv('./items_detail_test.csv')\n",
    "test_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# server"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " * Serving Flask app \"__main__\" (lazy loading)\n",
      " * Environment: production\n",
      "\u001b[31m   WARNING: This is a development server. Do not use it in a production deployment.\u001b[0m\n",
      "\u001b[2m   Use a production WSGI server instead.\u001b[0m\n",
      " * Debug mode: off\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " * Running on http://127.0.0.1:5000/ (Press CTRL+C to quit)\n",
      "127.0.0.1 - - [19/Jun/2020 12:51:57] \"\u001b[37mGET /knn/ALOXOO497B4LH HTTP/1.1\u001b[0m\" 200 -\n",
      "127.0.0.1 - - [19/Jun/2020 12:52:04] \"\u001b[37mGET /knn/ALOXOO497B4LH HTTP/1.1\u001b[0m\" 200 -\n"
     ]
    }
   ],
   "source": [
    "from flask import Flask,Response,make_response\n",
    "app = Flask(__name__)\n",
    "df = pd.read_csv('testForInput.csv')\n",
    "#'ALOXOO497B4LH'\n",
    "@app.route('/topN/<user_name>') # /review/\n",
    "def get_TopN_items_prediction(user_name):\n",
    "    \n",
    "    test = df[df['userID'] == user_name].drop(df.columns[3], axis=1)\n",
    "    columnsTitles=[\"userID\",\"itemID\",\"rating\"]\n",
    "    test=test.reindex(columns=columnsTitles)\n",
    "    predictions = prediction_algo.test(np.array(test))\n",
    "\n",
    "    top_n = get_top_n(predictions, n=10)\n",
    "    ret = []\n",
    "    # Print the recommended items for each user\n",
    "    for uid, user_ratings in top_n.items():\n",
    "        ret.append ( (uid, [iid for (iid, _) in user_ratings]) )\n",
    "    \n",
    "    items_info=[]\n",
    "    for item in ret[0][1]:\n",
    "        q =  test_data[test_data['item_id']==item]\n",
    "        item_info=[q['item_name'].tolist() ,q['img_url'].tolist()]\n",
    "        item_info=sum(item_info, [])\n",
    "        items_info.append(item_info)\n",
    "    \n",
    "    res_data = {\n",
    "        \"username\": ret[0][0],\n",
    "        \"items\": ret[0][1],\n",
    "        \"items_info\":items_info\n",
    "        }\n",
    "#     return jsonify(dict_data)\n",
    "    \n",
    "    resp = make_response(res_data)\n",
    "    resp.headers['Access-Control-Allow-Origin'] = '*'\n",
    "    \n",
    "    return resp,200\n",
    "\n",
    "@app.route('/knn/<user_name>') \n",
    "def get_k_nearest_neighbour_by_itme (user_name):\n",
    "    \n",
    "#     des_user_name = df[df['userID'] == user_name].drop(df.columns[3], axis=1)\n",
    "    i = 0 \n",
    "    for item in df['userID'].unique():\n",
    "        if item == user_name:\n",
    "            break\n",
    "        i += 1\n",
    "    \n",
    "    k_neighbors = knn_algo.get_neighbors(i, k=10)\n",
    "    \n",
    "#     toy_k_neighbors = knn_algo.get_neighbors(int(des_user_name.index[0]), k=10)\n",
    "#     res_data = ','.join(str(e) for e in toy_k_neighbors)\n",
    "    items = []\n",
    "    for e in k_neighbors:\n",
    "        items.append(df.iloc[int(e)]['itemID'])\n",
    "        \n",
    "    items_info=[]\n",
    "    for item in items:\n",
    "        q =  test_data[test_data['item_id']==item]\n",
    "        item_info=[q['item_name'].tolist() ,q['img_url'].tolist()]\n",
    "        item_info=sum(item_info, [])\n",
    "        items_info.append(item_info)\n",
    "    \n",
    "    res_data = {\n",
    "        \"username\": user_name,\n",
    "        \"items\": items,\n",
    "        \"items_info\":items_info\n",
    "        }\n",
    "   \n",
    "    resp = make_response(res_data)\n",
    "    resp.headers['Access-Control-Allow-Origin'] = '*'\n",
    "    return resp,200\n",
    "\n",
    "#     return ','.join(str(e) for e in toy_k_neighbors)\n",
    "    \n",
    "    \n",
    "\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    app.run()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range ( 2000 , 3000) :\n",
    "    print (knn_algo.get_neighbors(i, k=10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
